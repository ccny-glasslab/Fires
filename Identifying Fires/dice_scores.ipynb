{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "seven-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import metpy\n",
    "import datetime\n",
    "import s3fs\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from PIL import Image\n",
    "from pyresample import geometry, grid\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import laplace\n",
    "from skimage.filters import unsharp_mask\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.stats\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon = True)\n",
    "model = hub.load(\"https://tfhub.dev/captain-pool/esrgan-tf2/1\")\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "literary-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_npy_file(path, file, band):\n",
    "    \"\"\"\n",
    "    Returns the string name of another file from the same time for a given GOES band npy file,\n",
    "    or None if there is no such file in the given directory.\n",
    "    \n",
    "    Parameter path: The path where the returned file is located in\n",
    "    Precondition: path is a string to a directory relative to the current one, with .npy files\n",
    "    \n",
    "    Parameter file: A file from the same time the returned file should have\n",
    "    Precondition: file is a string with the name of the original file, and includes the path\n",
    "    \n",
    "    Parameter band: GOES band the returned file should be from\n",
    "    Precondition: band is a string of length 2\n",
    "    \"\"\"\n",
    "    for x in os.listdir(path):\n",
    "        if x[19:21] == band and file[23:37] == x[27:41]:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "front-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_img(img):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of errors for the given file without sharpening.\n",
    "    \n",
    "    Parameter path: The path to the given file\n",
    "    Precondition: path is a string\n",
    "    \n",
    "    Parameter file: The file to evaluate the error of\n",
    "    Precondition: file is a string\n",
    "    \"\"\"\n",
    "    height, width = img.shape\n",
    "    smallimg = resize(img, (round(height/2), round(width/2)))\n",
    "    control = resize(smallimg, (height, width))\n",
    "    return control\n",
    "\n",
    "def laplace_sharpening_img(img):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of errors for the given file using laplace sharpening.\n",
    "    \n",
    "    Parameter path: The path to the given file\n",
    "    Precondition: path is a string\n",
    "    \n",
    "    Parameter file: The file to perform laplace sharpening on\n",
    "    Precondition: file is a string\n",
    "    \"\"\"\n",
    "    height, width = img.shape\n",
    "    smallimg = resize(img, (round(height/2), round(width/2)))\n",
    "    blurryimg = resize(smallimg, (height, width))\n",
    "    laplace_edges = laplace(blurryimg)\n",
    "    sharpimg = blurryimg + 0.8*laplace_edges\n",
    "    return sharpimg\n",
    "\n",
    "def unsharpmask_sharpening_img(img):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of errors for the given file using unsharpmask sharpening. To normalize images,\n",
    "    each image is divided by its maximum value, and then multiplied by the same value after sharpening\n",
    "    is completed.\n",
    "    \n",
    "    Parameter path: The path to the given file\n",
    "    Precondition: path is a string\n",
    "    \n",
    "    Parameter file: The file to perform laplace sharpening on\n",
    "    Precondition: file is a str\n",
    "    \"\"\"\n",
    "    height, width = img.shape\n",
    "    smallimg = resize(img, (round(height/2), round(width/2)))\n",
    "    blurryimg = resize(smallimg, (height, width))\n",
    "    sharpimg = unsharp_mask(blurryimg/blurryimg.max(), radius=1, amount=1)*blurryimg.max()\n",
    "    return sharpimg\n",
    "\n",
    "def update_dict_img(fires, cloud_mask, img07, img14, data1, data2, data3, data4):\n",
    "    \"\"\"\n",
    "    Updates the dictionary with sharpening errors of a given file.\n",
    "    \n",
    "    Parameter path: The path to the given file\n",
    "    Precondition: path is a string\n",
    "    \n",
    "    Parameter file: The file to perform laplace sharpening on\n",
    "    Precondition: file is a string\n",
    "    \n",
    "    Parameter data: Dictionary containing sharpening errors\n",
    "    Precondition: data is a dict\n",
    "    \"\"\"\n",
    "    data07 = control_img(img07)\n",
    "    data14 = control_img(img14)\n",
    "    datafires = fire_mask(data07, data14)\n",
    "    datafires = np.logical_and(datafires, np.logical_not(cloud_mask))\n",
    "    data1['no_of_fires'].append(np.count_nonzero(datafires))\n",
    "    data1['dice_score'].append(dice_score(fires, datafires))\n",
    "    otherstats = other_stats(fires, datafires)\n",
    "    data1['TPR'].append(otherstats[2])\n",
    "    data1['PPV'].append(otherstats[3])\n",
    "    \n",
    "    data07 = laplace_sharpening_img(img07)\n",
    "    data14 = laplace_sharpening_img(img14)\n",
    "    datafires = fire_mask(data07, data14)\n",
    "    datafires = np.logical_and(datafires, np.logical_not(cloud_mask))\n",
    "    data2['no_of_fires'].append(np.count_nonzero(datafires))\n",
    "    data2['dice_score'].append(dice_score(fires, datafires))\n",
    "    otherstats = other_stats(fires, datafires)\n",
    "    data2['TPR'].append(otherstats[2])\n",
    "    data2['PPV'].append(otherstats[3])\n",
    "    \n",
    "    data07 = unsharpmask_sharpening_img(img07)\n",
    "    data14 = unsharpmask_sharpening_img(img14)\n",
    "    datafires = fire_mask(data07, data14)\n",
    "    datafires = np.logical_and(datafires, np.logical_not(cloud_mask))\n",
    "    data3['no_of_fires'].append(np.count_nonzero(datafires))\n",
    "    data3['dice_score'].append(dice_score(fires, datafires))\n",
    "    otherstats = other_stats(fires, datafires)\n",
    "    data3['TPR'].append(otherstats[2])\n",
    "    data3['PPV'].append(otherstats[3])\n",
    "    \n",
    "    data07 = esrgan_sharpening_img(img07)\n",
    "    data14 = esrgan_sharpening_img(img14)\n",
    "    datafires = fire_mask(data07, data14)\n",
    "    datafires = np.logical_and(datafires, np.logical_not(cloud_mask))\n",
    "    data4['no_of_fires'].append(np.count_nonzero(datafires))\n",
    "    data4['dice_score'].append(dice_score(fires, datafires))\n",
    "    otherstats = other_stats(fires, datafires)\n",
    "    data4['TPR'].append(otherstats[2])\n",
    "    data4['PPV'].append(otherstats[3])\n",
    "    \n",
    "def fire_threshold(img07, img14):\n",
    "    m = (330-210)/(340-295)\n",
    "    b = 210 - m*295\n",
    "    points = []\n",
    "    \n",
    "    fire_mask = (img14) < (m*img07 + b)\n",
    "    points = np.array(fire_mask.nonzero()).T\n",
    "    \n",
    "    for point in points:\n",
    "        save = point[0]\n",
    "        point[0] = point[1]\n",
    "        point[1] = 500 - save\n",
    "        \n",
    "    return points\n",
    "\n",
    "def fire_mask(img07, img14):\n",
    "    m = (330-210)/(340-295)\n",
    "    b = 210 - m*295\n",
    "    return (img14) < (m*img07 + b)\n",
    "\n",
    "def dice_score(x, y):\n",
    "    numerator = 2*np.count_nonzero(np.logical_and(x, y))\n",
    "    denominator = np.count_nonzero(x) + np.count_nonzero(y)\n",
    "    return numerator/denominator\n",
    "\n",
    "def other_stats(x, y):\n",
    "    false_positives = np.logical_and(np.logical_not(x), y)\n",
    "    false_negatives = np.logical_and(x, np.logical_not(y))\n",
    "    #true positive rate\n",
    "    TPR = np.count_nonzero(np.logical_and(x, y))/np.count_nonzero(x)\n",
    "    #positive predictive value\n",
    "    try:\n",
    "        PPV = np.count_nonzero(np.logical_and(x, y))/np.count_nonzero(y)\n",
    "    except ZeroDivisionError:\n",
    "        PPV = float('NaN')\n",
    "    return [np.count_nonzero(false_positives), np.count_nonzero(false_negatives), TPR, PPV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "suspended-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(array):\n",
    "    \"\"\"\n",
    "    Returns loaded .npy file.\n",
    "    \n",
    "    Parameter path: Path to load .npy file from\n",
    "    Precondition: path is a string\n",
    "    \"\"\"\n",
    "    result = np.zeros((array.shape[0], array.shape[1], 3))\n",
    "    result[:,:,0]= array\n",
    "    result[:,:,1]= array\n",
    "    result[:,:,2]= array\n",
    "    return result\n",
    "\n",
    "def preprocess_image(array):\n",
    "    \"\"\"\n",
    "    Returns preprocessed input array.\n",
    "    \n",
    "    Parameter array: array to preprocess\n",
    "    Precondition: array is a numpy array\n",
    "    \"\"\"\n",
    "    hr_image = array\n",
    "    hr_size = (tf.convert_to_tensor(hr_image.shape[:-1]) // 2) * 2\n",
    "    hr_image = tf.image.crop_to_bounding_box(hr_image, 0, 0, hr_size[0], hr_size[1])\n",
    "    hr_image = tf.cast(hr_image, tf.float32)\n",
    "    return tf.expand_dims(hr_image, 0)\n",
    "\n",
    "def downscale_image(image):\n",
    "    \"\"\"\n",
    "    Returns low resolution image after scaling down input image using nearest neighbor downsampling.\n",
    "\n",
    "    Parameter image: 3D of 4D tensor of preprocessed image\n",
    "    Precondition: image is a tensor\n",
    "    \"\"\"\n",
    "    height, width = image.shape\n",
    "    result = np.zeros((image.shape[0]//2, image.shape[1]//2, 3))\n",
    "    smallimg = resize(image, (round(height/2), round(width/2)))\n",
    "    result[:,:,0] = smallimg\n",
    "    result[:,:,1] = smallimg\n",
    "    result[:,:,2] = smallimg\n",
    "    lr_image = tf.expand_dims(result, 0)\n",
    "    lr_image = tf.cast(lr_image, tf.float32)\n",
    "    return lr_image\n",
    "\n",
    "def esrgan_sharpening_img(image):\n",
    "    \"\"\"\n",
    "    Returns dictionary containing errors after using the ESRGAN model.\n",
    "    \n",
    "    Parameter path: path of image not including file name\n",
    "    Precondition: path is a string\n",
    "    \n",
    "    Parameter file: file of the image\n",
    "    Precondition: file is a string of a .npy file\n",
    "    \"\"\"\n",
    "    hr_image = preprocess_image(load_image(image))\n",
    "    lr_image = downscale_image(image)\n",
    "    fake_image = model(lr_image)\n",
    "    fake_image = tf.squeeze(fake_image)\n",
    "\n",
    "    hr_image = tf.squeeze(hr_image).numpy()\n",
    "    lr_image = tf.squeeze(lr_image).numpy()\n",
    "    lr_image = resize(lr_image, (hr_image.shape[0], hr_image.shape[1], 3)).ravel()\n",
    "    fake_image = resize(fake_image.numpy(), (hr_image.shape[0], hr_image.shape[1], 3))\n",
    "\n",
    "    return np.mean(fake_image, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-sigma",
   "metadata": {},
   "source": [
    "# Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "coordinate-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "filedates = set()\n",
    "files = []\n",
    "\n",
    "for file in os.listdir('../../GOES_Files/npy_files'):\n",
    "    filedates.add(file[27:41])\n",
    "\n",
    "for file in os.listdir('../../GOES_Files/clear_sky_mask'):\n",
    "    if file[23:37] in filedates:\n",
    "        files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bacterial-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = []\n",
    "std = []\n",
    "path = '../../GOES_Files/npy_files/'\n",
    "pathCM = '../../GOES_Files/clear_sky_mask/'\n",
    "fires_initial = []\n",
    "fires_final_control = {'no_of_fires':[], 'dice_score':[], 'TPR':[], 'PPV':[]}\n",
    "fires_final_lp = copy.deepcopy(fires_final_control)\n",
    "fires_final_um = copy.deepcopy(fires_final_control)\n",
    "fires_final_ml = copy.deepcopy(fires_final_control)\n",
    "\n",
    "x = 0\n",
    "\n",
    "while x < 100:\n",
    "    try:\n",
    "        CM = random.choice(files)\n",
    "        files.remove(CM)\n",
    "\n",
    "        file07 = find_npy_file('../../GOES_Files/npy_files', CM, '07')\n",
    "        file14 = find_npy_file('../../GOES_Files/npy_files', CM, '14')\n",
    "        img07 = np.load(path + file07)\n",
    "        img14 = np.load(path + file14)\n",
    "\n",
    "        cloud_mask = np.load(pathCM + CM)\n",
    "        cloud_mask = cloud_mask.astype(bool)\n",
    "        fires = np.logical_and(fire_mask(img07, img14), np.logical_not(cloud_mask))\n",
    "        \n",
    "        if np.count_nonzero(fires) != 0:\n",
    "            fires_initial.append(np.count_nonzero(fires))\n",
    "            update_dict_img(fires, cloud_mask, img07, img14, fires_final_control, fires_final_lp, fires_final_um, fires_final_ml)\n",
    "\n",
    "            x += 1\n",
    "\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "italian-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(stat):\n",
    "    data = [fires_final_control, fires_final_lp, fires_final_um, fires_final_ml]\n",
    "    datanames = ['Control', 'Laplace', 'Unsharp Mask', 'ESRGAN']\n",
    "    print(stat)\n",
    "    for x in range(len(data)):\n",
    "        print(f'     {datanames[x]} {round(np.nanmean(data[x][stat]), 4)} +/- {round(2*np.nanstd(data[x][stat]), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "beneficial-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.8911\n",
      "no_of_fires\n",
      "     Control 9.5446 +/- 27.876\n",
      "     Laplace 12.1188 +/- 30.8048\n",
      "     Unsharp Mask 10.7624 +/- 29.0144\n",
      "     ESRGAN 9.92 +/- 26.6664\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(fires_initial), 4))\n",
    "results('no_of_fires')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "chinese-notification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_score\n",
      "     Control 0.7126 +/- 0.6447\n",
      "     Laplace 0.7444 +/- 0.4975\n",
      "     Unsharp Mask 0.7301 +/- 0.5894\n",
      "     ESRGAN 0.8106 +/- 0.5634\n"
     ]
    }
   ],
   "source": [
    "results('dice_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "funny-peter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR\n",
      "     Control 0.7294 +/- 0.706\n",
      "     Laplace 0.8614 +/- 0.5342\n",
      "     Unsharp Mask 0.7914 +/- 0.6486\n",
      "     ESRGAN 0.8333 +/- 0.586\n"
     ]
    }
   ],
   "source": [
    "results('TPR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "confident-modem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPV\n",
      "     Control 0.8154 +/- 0.4647\n",
      "     Laplace 0.6929 +/- 0.4883\n",
      "     Unsharp Mask 0.7552 +/- 0.4815\n",
      "     ESRGAN 0.8538 +/- 0.417\n"
     ]
    }
   ],
   "source": [
    "results('PPV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "personal-mainstream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-1.7562955738269859, pvalue=0.08057619334530504)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.ttest_ind(fires_final_lp['dice_score'], fires_final_ml['dice_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-fireplace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
