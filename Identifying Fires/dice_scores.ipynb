{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "specialized-russian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sharedData2/nshakoor/.conda/envs/fires/lib/python3.7/site-packages/pyresample/bilinear/__init__.py:49: UserWarning: XArray and/or zarr not found, XArrayBilinearResampler won't be available.\n",
      "  warnings.warn(\"XArray and/or zarr not found, XArrayBilinearResampler won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import metpy\n",
    "import datetime\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from PIL import Image\n",
    "from pyresample import geometry, grid\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import laplace\n",
    "from skimage.filters import unsharp_mask\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon = True)\n",
    "model = hub.load(\"https://tfhub.dev/captain-pool/esrgan-tf2/1\")\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acknowledged-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_npy_file(path, file, band):\n",
    "    \"\"\"\n",
    "    Returns the string name of another file from the same time for a given GOES band npy file,\n",
    "    or None if there is no such file in the given directory.\n",
    "    \n",
    "    Parameter path: The path where the returned file is located in\n",
    "    Precondition: path is a string to a directory relative to the current one, with .npy files\n",
    "    \n",
    "    Parameter file: A file from the same time the returned file should have\n",
    "    Precondition: file is a string with the name of the original file, and includes the path\n",
    "    \n",
    "    Parameter band: GOES band the returned file should be from\n",
    "    Precondition: band is a string of length 2\n",
    "    \"\"\"\n",
    "    for x in os.listdir(path):\n",
    "        if x[19:21] == band and file[23:37] == x[27:41]:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "viral-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_img(img):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of errors for the given file without sharpening.\n",
    "    \n",
    "    Parameter path: The path to the given file\n",
    "    Precondition: path is a string\n",
    "    \n",
    "    Parameter file: The file to evaluate the error of\n",
    "    Precondition: file is a string\n",
    "    \"\"\"\n",
    "    height, width = img.shape\n",
    "    smallimg = resize(img, (round(height/2), round(width/2)))\n",
    "    control = resize(smallimg, (height, width))\n",
    "    return control\n",
    "\n",
    "def laplace_sharpening_img(img):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of errors for the given file using laplace sharpening.\n",
    "    \n",
    "    Parameter path: The path to the given file\n",
    "    Precondition: path is a string\n",
    "    \n",
    "    Parameter file: The file to perform laplace sharpening on\n",
    "    Precondition: file is a string\n",
    "    \"\"\"\n",
    "    height, width = img.shape\n",
    "    smallimg = resize(img, (round(height/2), round(width/2)))\n",
    "    blurryimg = resize(smallimg, (height, width))\n",
    "    laplace_edges = laplace(blurryimg)\n",
    "    sharpimg = blurryimg + laplace_edges\n",
    "    return sharpimg\n",
    "\n",
    "def unsharpmask_sharpening_img(img):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of errors for the given file using unsharpmask sharpening. To normalize images,\n",
    "    each image is divided by its maximum value, and then multiplied by the same value after sharpening\n",
    "    is completed.\n",
    "    \n",
    "    Parameter path: The path to the given file\n",
    "    Precondition: path is a string\n",
    "    \n",
    "    Parameter file: The file to perform laplace sharpening on\n",
    "    Precondition: file is a str\n",
    "    \"\"\"\n",
    "    height, width = img.shape\n",
    "    smallimg = resize(img, (round(height/2), round(width/2)))\n",
    "    blurryimg = resize(smallimg, (height, width))\n",
    "    sharpimg = unsharp_mask(blurryimg/blurryimg.max(), radius=1, amount=1)*blurryimg.max()\n",
    "    return sharpimg\n",
    "\n",
    "def update_dict_img(img07, img14, data1, data2, data3, data4):\n",
    "    \"\"\"\n",
    "    Updates the dictionary with sharpening errors of a given file.\n",
    "    \n",
    "    Parameter path: The path to the given file\n",
    "    Precondition: path is a string\n",
    "    \n",
    "    Parameter file: The file to perform laplace sharpening on\n",
    "    Precondition: file is a string\n",
    "    \n",
    "    Parameter data: Dictionary containing sharpening errors\n",
    "    Precondition: data is a dict\n",
    "    \"\"\"\n",
    "    m = (330-210)/(340-295)\n",
    "    b = 210 - m*295\n",
    "    fire_mask = (img14) < (m*img07 + b)\n",
    "    \n",
    "    data07 = control_img(img07)\n",
    "    data14 = control_img(img14)\n",
    "    fires = (data14) < (m*data07 + b)\n",
    "    data1[0].append(len(fire_threshold(data07, data14)))\n",
    "    data1[1].append(dice_score(fire_mask, fires))\n",
    "    \n",
    "    data07 = laplace_sharpening_img(img07)\n",
    "    data14 = laplace_sharpening_img(img14)\n",
    "    fires = (data14) < (m*data07 + b)\n",
    "    data2[0].append(len(fire_threshold(data07, data14)))\n",
    "    data2[1].append(dice_score(fire_mask, fires))\n",
    "    \n",
    "    data07 = unsharpmask_sharpening_img(img07)\n",
    "    data14 = unsharpmask_sharpening_img(img14)\n",
    "    fires = (data14) < (m*data07 + b)\n",
    "    data3[0].append(len(fire_threshold(data07, data14)))\n",
    "    data3[1].append(dice_score(fire_mask, fires))\n",
    "    \n",
    "#     data07 = esrgan_sharpening_img(img07)\n",
    "#     data14 = esrgan_sharpening_img(img14)\n",
    "#     data4.append(len(fire_threshold(data07, data14)))\n",
    "    \n",
    "def fire_threshold(img07, img14):\n",
    "    m = (330-210)/(340-295)\n",
    "    b = 210 - m*295\n",
    "    points = []\n",
    "    \n",
    "    fire_mask = (img14) < (m*img07 + b)\n",
    "    points = np.array(fire_mask.nonzero()).T\n",
    "    \n",
    "    for point in points:\n",
    "        save = point[0]\n",
    "        point[0] = point[1]\n",
    "        point[1] = 500 - save\n",
    "        \n",
    "    return points\n",
    "\n",
    "def dice_score(x, y):\n",
    "    numerator = 2*np.count_nonzero(np.logical_and(x, y))\n",
    "    denominator = len(x) + len(y)\n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "applicable-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(array):\n",
    "    \"\"\"\n",
    "    Returns loaded .npy file.\n",
    "    \n",
    "    Parameter path: Path to load .npy file from\n",
    "    Precondition: path is a string\n",
    "    \"\"\"\n",
    "    result = np.zeros((array.shape[0], array.shape[1], 3))\n",
    "    result[:,:,0]= array\n",
    "    result[:,:,1]= array\n",
    "    result[:,:,2]= array\n",
    "    return result\n",
    "\n",
    "def preprocess_image(array):\n",
    "    \"\"\"\n",
    "    Returns preprocessed input array.\n",
    "    \n",
    "    Parameter array: array to preprocess\n",
    "    Precondition: array is a numpy array\n",
    "    \"\"\"\n",
    "    hr_image = array\n",
    "    hr_size = (tf.convert_to_tensor(hr_image.shape[:-1]) // 2) * 2\n",
    "    hr_image = tf.image.crop_to_bounding_box(hr_image, 0, 0, hr_size[0], hr_size[1])\n",
    "    hr_image = tf.cast(hr_image, tf.float32)\n",
    "    return tf.expand_dims(hr_image, 0)\n",
    "\n",
    "def downscale_image(image):\n",
    "    \"\"\"\n",
    "    Returns low resolution image after scaling down input image using nearest neighbor downsampling.\n",
    "\n",
    "    Parameter image: 3D of 4D tensor of preprocessed image\n",
    "    Precondition: image is a tensor\n",
    "    \"\"\"\n",
    "    height, width = image.shape\n",
    "    result = np.zeros((image.shape[0]//2, image.shape[1]//2, 3))\n",
    "    smallimg = resize(image, (round(height/2), round(width/2)))\n",
    "    result[:,:,0] = smallimg\n",
    "    result[:,:,1] = smallimg\n",
    "    result[:,:,2] = smallimg\n",
    "    lr_image = tf.expand_dims(result, 0)\n",
    "    lr_image = tf.cast(lr_image, tf.float32)\n",
    "    return lr_image\n",
    "\n",
    "def esrgan_sharpening(image):\n",
    "    \"\"\"\n",
    "    Returns dictionary containing errors after using the ESRGAN model.\n",
    "    \n",
    "    Parameter path: path of image not including file name\n",
    "    Precondition: path is a string\n",
    "    \n",
    "    Parameter file: file of the image\n",
    "    Precondition: file is a string of a .npy file\n",
    "    \"\"\"\n",
    "    hr_image = preprocess_image(load_image(image))\n",
    "    lr_image = downscale_image(image)\n",
    "    fake_image = model(lr_image)\n",
    "    fake_image = tf.squeeze(fake_image)\n",
    "\n",
    "    hr_image = tf.squeeze(hr_image).numpy()\n",
    "    lr_image = tf.squeeze(lr_image).numpy()\n",
    "    lr_image = resize(lr_image, (hr_image.shape[0], hr_image.shape[1], 3)).ravel()\n",
    "    fake_image = resize(fake_image.numpy(), (hr_image.shape[0], hr_image.shape[1], 3)).ravel()\n",
    "    hr_image = hr_image.ravel()\n",
    "\n",
    "    control_mae = mean_absolute_error(hr_image, lr_image)\n",
    "    control_rmse = mean_squared_error(hr_image, lr_image, squared=False)\n",
    "\n",
    "    mae = mean_absolute_error(hr_image, fake_image)\n",
    "    rmse = mean_squared_error(hr_image, fake_image, squared=False)\n",
    "    return {'Control_MAE*': control_mae, 'Control_RMSE*': control_rmse, 'SR_MAE': mae, 'SR_RMSE': rmse}\n",
    "\n",
    "def esrgan_sharpening_img(image):\n",
    "    \"\"\"\n",
    "    Returns dictionary containing errors after using the ESRGAN model.\n",
    "    \n",
    "    Parameter path: path of image not including file name\n",
    "    Precondition: path is a string\n",
    "    \n",
    "    Parameter file: file of the image\n",
    "    Precondition: file is a string of a .npy file\n",
    "    \"\"\"\n",
    "    hr_image = preprocess_image(load_image(image))\n",
    "    lr_image = downscale_image(image)\n",
    "    fake_image = model(lr_image)\n",
    "    fake_image = tf.squeeze(fake_image)\n",
    "\n",
    "    hr_image = tf.squeeze(hr_image).numpy()\n",
    "    lr_image = tf.squeeze(lr_image).numpy()\n",
    "    lr_image = resize(lr_image, (hr_image.shape[0], hr_image.shape[1], 3)).ravel()\n",
    "    fake_image = resize(fake_image.numpy(), (hr_image.shape[0], hr_image.shape[1], 3)).ravel()\n",
    "    hr_image = hr_image.ravel()\n",
    "\n",
    "    return hr_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-translator",
   "metadata": {},
   "source": [
    "# Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "needed-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "filedates = set()\n",
    "files = []\n",
    "\n",
    "for file in os.listdir('../../GOES_Files/npy_files'):\n",
    "    filedates.add(file[27:41])\n",
    "\n",
    "for file in os.listdir('../../GOES_Files/clear_sky_mask'):\n",
    "    if file[23:37] in filedates:\n",
    "        files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "corresponding-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = []\n",
    "std = []\n",
    "path = '../../GOES_Files/npy_files/'\n",
    "pathCM = '../../GOES_Files/clear_sky_mask/'\n",
    "fires_initial = [[], []]\n",
    "fires_final_control = [[], []]\n",
    "fires_final_lp = [[], []]\n",
    "fires_final_um = [[], []]\n",
    "fires_final_ml = [[], []]\n",
    "\n",
    "x = 0\n",
    "\n",
    "while x < 10:\n",
    "    try:\n",
    "        CM = random.choice(files)\n",
    "        files.remove(CM)\n",
    "\n",
    "        file07 = find_npy_file('../../GOES_Files/npy_files', CM, '07')\n",
    "        file14 = find_npy_file('../../GOES_Files/npy_files', CM, '14')\n",
    "\n",
    "        img07 = np.load(path + file07)\n",
    "        img14 = np.load(path + file14)\n",
    "\n",
    "        mask = np.load(pathCM + CM)\n",
    "        mask = mask.astype(bool)\n",
    "#         img07[mask] = 0\n",
    "#         img14[mask] = 0\n",
    "\n",
    "        fires_initial.append(len(fire_threshold(img07, img14)))\n",
    "\n",
    "        update_dict_img(img07, img14, fires_final_control, fires_final_lp, fires_final_um, fires_final_ml)\n",
    "\n",
    "        x += 1\n",
    "\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "musical-diesel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "0.0\n",
      "0.3\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#mean number of fires for each image\n",
    "print(np.mean(fires_initial[0]))\n",
    "print(np.mean(fires_final_control[0]))\n",
    "print(np.mean(fires_final_lp[0]))\n",
    "print(np.mean(fires_final_um[0]))\n",
    "# print(np.mean(fires_final_ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "metric-perception",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "0.0\n",
      "0.0004\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#mean dice score\n",
    "print(np.mean(fires_initial[1]))\n",
    "print(np.mean(fires_final_control[1]))\n",
    "print(np.mean(fires_final_lp[1]))\n",
    "print(np.mean(fires_final_um[1]))\n",
    "# print(np.mean(fires_final_ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "later-purpose",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fires_final_lp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-ozone",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
