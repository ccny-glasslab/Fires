{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prerequisite-vacation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-31 16:38:12.455770: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2022-12-31 16:38:12.455894: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2022-12-31 16:38:12.455907: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/sharedData2/nshakoor/.conda/envs/fires/lib/python3.7/site-packages/pyresample/bilinear/__init__.py:49: UserWarning: XArray and/or zarr not found, XArrayBilinearResampler won't be available.\n",
      "  warnings.warn(\"XArray and/or zarr not found, XArrayBilinearResampler won't be available.\")\n",
      "2022-12-31 16:38:14.015020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-12-31 16:38:14.021393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:83:00.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2022-12-31 16:38:14.022153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \n",
      "pciBusID: 0000:84:00.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2022-12-31 16:38:14.022240: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2022-12-31 16:38:14.024063: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-12-31 16:38:14.026224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-12-31 16:38:14.026543: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-12-31 16:38:14.028721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-12-31 16:38:14.029781: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-12-31 16:38:14.029863: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-31 16:38:14.029877: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1592] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-31 16:38:14.030288: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-12-31 16:38:14.038455: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400210000 Hz\n",
      "2022-12-31 16:38:14.039510: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55683f5378b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-31 16:38:14.039528: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-12-31 16:38:14.157694: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55683f59db60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-31 16:38:14.157730: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
      "2022-12-31 16:38:14.157737: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7\n",
      "2022-12-31 16:38:14.157959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-12-31 16:38:14.157971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import metpy\n",
    "import datetime\n",
    "import s3fs\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from PIL import Image\n",
    "from pyresample import geometry, grid\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import laplace\n",
    "from skimage.filters import unsharp_mask\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.stats\n",
    "from scipy.signal import wiener\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon = True)\n",
    "model = hub.load(\"https://tfhub.dev/captain-pool/esrgan-tf2/1\")\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bibliographic-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_npy_file(path, file, band):\n",
    "    \"\"\"\n",
    "    Returns the string name of another file from the same time for a given GOES band npy file,\n",
    "    or None if there is no such file in the given directory.\n",
    "    \n",
    "    Parameter path: The path where the returned file is located in\n",
    "    Precondition: path is a string to a directory relative to the current one, with .npy files\n",
    "    \n",
    "    Parameter file: A file from the same time the returned file should have\n",
    "    Precondition: file is a string with the name of the original file, and includes the path\n",
    "    \n",
    "    Parameter band: GOES band the returned file should be from\n",
    "    Precondition: band is a string of length 2\n",
    "    \"\"\"\n",
    "    for x in os.listdir(path):\n",
    "        if x[19:21] == band and file[23:37] == x[27:41]:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "massive-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_img(img):\n",
    "    height, width = img.shape\n",
    "    smallimg = resize(img, (round(height/2), round(width/2)))\n",
    "    control = resize(smallimg, (height, width))\n",
    "    return control\n",
    "\n",
    "def laplace_sharpening_img(img):\n",
    "    height, width = img.shape\n",
    "    smallimg = resize(img, (round(height/2), round(width/2)))\n",
    "    blurryimg = resize(smallimg, (height, width))\n",
    "    laplace_edges = laplace(blurryimg)\n",
    "    sharpimg = blurryimg + 0.8*laplace_edges\n",
    "    return sharpimg\n",
    "\n",
    "def unsharpmask_sharpening_img(img):\n",
    "    height, width = img.shape\n",
    "    smallimg = resize(img, (round(height/2), round(width/2)))\n",
    "    blurryimg = resize(smallimg, (height, width))\n",
    "    sharpimg = unsharp_mask(blurryimg/blurryimg.max(), radius=1, amount=1)*blurryimg.max()\n",
    "    return sharpimg\n",
    "\n",
    "def wiener_sharpening_img(img):\n",
    "    height, width = img.shape\n",
    "    smallimg = resize(img, (round(height/2), round(width/2)))\n",
    "    blurryimg = resize(smallimg, (height, width))\n",
    "    sharpimg = wiener(blurryimg/blurryimg.max())*blurryimg.max()\n",
    "    return sharpimg\n",
    "\n",
    "def update_dict_img(fires, cloud_mask, img07, img14, data1, data2, data3, data4, data5):\n",
    "    \"\"\"\n",
    "    Updates the dictionary with sharpening errors of a given file.\n",
    "    \n",
    "    Parameter path: The path to the given file\n",
    "    Precondition: path is a string\n",
    "    \n",
    "    Parameter file: The file to perform laplace sharpening on\n",
    "    Precondition: file is a string\n",
    "    \n",
    "    Parameter data: Dictionary containing sharpening errors\n",
    "    Precondition: data is a dict\n",
    "    \"\"\"\n",
    "    data07 = control_img(img07)\n",
    "    data14 = control_img(img14)\n",
    "    datafires = fire_mask(data07, data14)\n",
    "    datafires = np.logical_and(datafires, np.logical_not(cloud_mask))\n",
    "    data1['no_of_fires'].append(np.count_nonzero(datafires))\n",
    "    data1['dice_score'].append(dice_score(fires, datafires))\n",
    "    otherstats = other_stats(fires, datafires)\n",
    "    data1['TPR'].append(otherstats[2])\n",
    "    data1['PPV'].append(otherstats[3])\n",
    "    \n",
    "    data07 = laplace_sharpening_img(img07)\n",
    "    data14 = laplace_sharpening_img(img14)\n",
    "    datafires = fire_mask(data07, data14)\n",
    "    datafires = np.logical_and(datafires, np.logical_not(cloud_mask))\n",
    "    data2['no_of_fires'].append(np.count_nonzero(datafires))\n",
    "    data2['dice_score'].append(dice_score(fires, datafires))\n",
    "    otherstats = other_stats(fires, datafires)\n",
    "    data2['TPR'].append(otherstats[2])\n",
    "    data2['PPV'].append(otherstats[3])\n",
    "    \n",
    "    data07 = unsharpmask_sharpening_img(img07)\n",
    "    data14 = unsharpmask_sharpening_img(img14)\n",
    "    datafires = fire_mask(data07, data14)\n",
    "    datafires = np.logical_and(datafires, np.logical_not(cloud_mask))\n",
    "    data3['no_of_fires'].append(np.count_nonzero(datafires))\n",
    "    data3['dice_score'].append(dice_score(fires, datafires))\n",
    "    otherstats = other_stats(fires, datafires)\n",
    "    data3['TPR'].append(otherstats[2])\n",
    "    data3['PPV'].append(otherstats[3])\n",
    "    \n",
    "    data07 = wiener_sharpening_img(img07)\n",
    "    data14 = wiener_sharpening_img(img14)\n",
    "    datafires = fire_mask(data07, data14)\n",
    "    datafires = np.logical_and(datafires, np.logical_not(cloud_mask))\n",
    "    data4['no_of_fires'].append(np.count_nonzero(datafires))\n",
    "    data4['dice_score'].append(dice_score(fires, datafires))\n",
    "    otherstats = other_stats(fires, datafires)\n",
    "    data4['TPR'].append(otherstats[2])\n",
    "    data4['PPV'].append(otherstats[3])\n",
    "    \n",
    "    data07 = esrgan_sharpening_img(img07)\n",
    "    data14 = esrgan_sharpening_img(img14)\n",
    "    datafires = fire_mask(data07, data14)\n",
    "    datafires = np.logical_and(datafires, np.logical_not(cloud_mask))\n",
    "    data5['no_of_fires'].append(np.count_nonzero(datafires))\n",
    "    data5['dice_score'].append(dice_score(fires, datafires))\n",
    "    otherstats = other_stats(fires, datafires)\n",
    "    data5['TPR'].append(otherstats[2])\n",
    "    data5['PPV'].append(otherstats[3])\n",
    "    \n",
    "def fire_threshold(img07, img14):\n",
    "    m = (330-210)/(340-295)\n",
    "    b = 210 - m*295\n",
    "    points = []\n",
    "    \n",
    "    fire_mask = (img14) < (m*img07 + b)\n",
    "    points = np.array(fire_mask.nonzero()).T\n",
    "    \n",
    "    for point in points:\n",
    "        save = point[0]\n",
    "        point[0] = point[1]\n",
    "        point[1] = 500 - save\n",
    "        \n",
    "    return points\n",
    "\n",
    "def fire_mask(img07, img14):\n",
    "    m = (330-210)/(340-295)\n",
    "    b = 210 - m*295\n",
    "    return (img14) < (m*img07 + b)\n",
    "\n",
    "def dice_score(x, y):\n",
    "    numerator = 2*np.count_nonzero(np.logical_and(x, y))\n",
    "    denominator = np.count_nonzero(x) + np.count_nonzero(y)\n",
    "    return numerator/denominator\n",
    "\n",
    "def other_stats(x, y):\n",
    "    false_positives = np.logical_and(np.logical_not(x), y)\n",
    "    false_negatives = np.logical_and(x, np.logical_not(y))\n",
    "    #true positive rate\n",
    "    TPR = np.count_nonzero(np.logical_and(x, y))/np.count_nonzero(x)\n",
    "    #positive predictive value\n",
    "    try:\n",
    "        PPV = np.count_nonzero(np.logical_and(x, y))/np.count_nonzero(y)\n",
    "    except ZeroDivisionError:\n",
    "        PPV = float('NaN')\n",
    "    return [np.count_nonzero(false_positives), np.count_nonzero(false_negatives), TPR, PPV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cognitive-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = 275\n",
    "maxi = 400\n",
    "\n",
    "def load_image(array):\n",
    "    new_array = 255*((array - mini) / (maxi - mini))\n",
    "    result = np.zeros((array.shape[0], array.shape[1], 3))\n",
    "    result[:,:,0]= new_array\n",
    "    result[:,:,1]= new_array\n",
    "    result[:,:,2]= new_array\n",
    "    return result\n",
    "\n",
    "def preprocess_image(array):\n",
    "    height, width, depth = array.shape\n",
    "    result = np.zeros((array.shape[0]//2, array.shape[1]//2, 3))\n",
    "    hr_image = result[:,:,:]\n",
    "    smallimg = resize(array, (round(height/2), round(width/2), 3))\n",
    "    hr_image = smallimg\n",
    "    \n",
    "    hr_size = tf.convert_to_tensor(hr_image.shape[:-1])\n",
    "    hr_image = tf.image.crop_to_bounding_box(hr_image, 0, 0, hr_size[0], hr_size[1])\n",
    "    hr_image = tf.cast(hr_image, tf.float32)\n",
    "    return tf.expand_dims(hr_image, 0)\n",
    "\n",
    "def esrgan_sharpening_img(image):\n",
    "    \"\"\"\n",
    "    Returns dictionary containing errors after using the ESRGAN model.\n",
    "    \n",
    "    Parameter path: path of image not including file name\n",
    "    Precondition: path is a string\n",
    "    \n",
    "    Parameter file: file of the image\n",
    "    Precondition: file is a string of a .npy file\n",
    "    \"\"\"\n",
    "    hr_image = preprocess_image(load_image(image))    \n",
    "    fake_image = model(hr_image)\n",
    "    fake_image = tf.squeeze(fake_image)\n",
    "    fake_image = np.mean(fake_image, axis=2)\n",
    "    fake_image = resize(fake_image, (image.shape[0], image.shape[1]))\n",
    "    return (fake_image/255)*(maxi - mini) + mini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-carol",
   "metadata": {},
   "source": [
    "# Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eligible-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "filedates = set()\n",
    "files = []\n",
    "\n",
    "for file in os.listdir('../goes_files/npy_files'):\n",
    "    filedates.add(file[27:41])\n",
    "\n",
    "for file in os.listdir('../goes_files/clear_sky_mask'):\n",
    "    if file[23:37] in filedates:\n",
    "        files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "broken-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../goes_files/npy_files/'\n",
    "pathCM = '../goes_files/clear_sky_mask/'\n",
    "fires_initial = []\n",
    "fires_final_control = {'no_of_fires':[], 'dice_score':[], 'TPR':[], 'PPV':[]}\n",
    "fires_final_lp = copy.deepcopy(fires_final_control)\n",
    "fires_final_um = copy.deepcopy(fires_final_control)\n",
    "fires_final_wr = copy.deepcopy(fires_final_control)\n",
    "fires_final_ml = copy.deepcopy(fires_final_control)\n",
    "\n",
    "x = 0\n",
    "\n",
    "while x < 50:\n",
    "#     try:\n",
    "    CM = random.choice(files)\n",
    "    files.remove(CM)\n",
    "\n",
    "    file07 = find_npy_file('../goes_files/npy_files', CM, '07')\n",
    "    file14 = find_npy_file('../goes_files/npy_files', CM, '14')\n",
    "    img07 = np.load(path + file07)\n",
    "    img14 = np.load(path + file14)\n",
    "\n",
    "    cloud_mask = np.load(pathCM + CM)\n",
    "    cloud_mask = cloud_mask.astype(bool)\n",
    "    fires = np.logical_and(fire_mask(img07, img14), np.logical_not(cloud_mask))\n",
    "\n",
    "    if np.count_nonzero(fires) != 0:\n",
    "        fires_initial.append(np.count_nonzero(fires))\n",
    "        update_dict_img(fires, cloud_mask, img07, img14, fires_final_control, fires_final_lp, fires_final_um, fires_final_wr, fires_final_ml)\n",
    "\n",
    "        x += 1\n",
    "\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "molecular-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(stat):\n",
    "    data = [fires_final_control, fires_final_lp, fires_final_um, fires_final_wr, fires_final_ml]\n",
    "    datanames = ['Control', 'Laplace', 'Unsharp Mask', 'Wiener', 'ESRGAN']\n",
    "    print(stat)\n",
    "    for x in range(len(data)):\n",
    "        print(f'     {datanames[x]} {round(np.nanmean(data[x][stat]), 4)} +/- {round(2*np.nanstd(data[x][stat]), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "enormous-apache",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.02\n",
      "no_of_fires\n",
      "     Control 16.88 +/- 50.6686\n",
      "     Laplace 20.68 +/- 54.7773\n",
      "     Unsharp Mask 19.08 +/- 53.8856\n",
      "     Wiener 15.82 +/- 49.6382\n",
      "     ESRGAN 16.54 +/- 48.2464\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(fires_initial), 4))\n",
    "results('no_of_fires')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "statewide-helping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_score\n",
      "     Control 0.7457 +/- 0.4995\n",
      "     Laplace 0.7745 +/- 0.3195\n",
      "     Unsharp Mask 0.7809 +/- 0.3964\n",
      "     Wiener 0.6715 +/- 0.6413\n",
      "     ESRGAN 0.8499 +/- 0.3775\n"
     ]
    }
   ],
   "source": [
    "results('dice_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "broadband-collectible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR\n",
      "     Control 0.7657 +/- 0.5864\n",
      "     Laplace 0.8838 +/- 0.3598\n",
      "     Unsharp Mask 0.8388 +/- 0.4565\n",
      "     Wiener 0.6953 +/- 0.7156\n",
      "     ESRGAN 0.8536 +/- 0.435\n"
     ]
    }
   ],
   "source": [
    "results('TPR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "linear-array",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPV\n",
      "     Control 0.7986 +/- 0.3902\n",
      "     Laplace 0.7075 +/- 0.3624\n",
      "     Unsharp Mask 0.7682 +/- 0.3749\n",
      "     Wiener 0.7788 +/- 0.4135\n",
      "     ESRGAN 0.8678 +/- 0.3581\n"
     ]
    }
   ],
   "source": [
    "results('PPV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "little-transfer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-4.747571072327352, pvalue=2.876945880922905e-06)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.ttest_ind(fires_final_control['dice_score'], fires_final_ml['dice_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "welsh-replica",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-4.399930686993859, pvalue=1.392302946504219e-05)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.ttest_ind(fires_final_lp['dice_score'], fires_final_ml['dice_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "patient-airfare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-4.113522777478705, pvalue=4.737109773734443e-05)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.ttest_ind(fires_final_um['dice_score'], fires_final_ml['dice_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "stretch-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = []\n",
    "std = []\n",
    "path = '../../GOES_Files/npy_files/'\n",
    "pathCM = '../../GOES_Files/clear_sky_mask/'\n",
    "fires_initial = []\n",
    "fires_final_control = {'no_of_fires':[], 'dice_score':[], 'TPR':[], 'PPV':[]}\n",
    "fires_final_lp = copy.deepcopy(fires_final_control)\n",
    "fires_final_um = copy.deepcopy(fires_final_control)\n",
    "fires_final_wr = copy.deepcopy(fires_final_control)\n",
    "fires_final_ml = copy.deepcopy(fires_final_control)\n",
    "\n",
    "x = 0\n",
    "\n",
    "while x < 20:\n",
    "    try:\n",
    "        CM = random.choice(files)\n",
    "        files.remove(CM)\n",
    "\n",
    "        file07 = find_npy_file('../../GOES_Files/npy_files', CM, '07')\n",
    "        file14 = find_npy_file('../../GOES_Files/npy_files', CM, '14')\n",
    "        img07 = np.load(path + file07)\n",
    "        img14 = np.load(path + file14)\n",
    "\n",
    "        cloud_mask = np.load(pathCM + CM)\n",
    "        cloud_mask = cloud_mask.astype(bool)\n",
    "        fires = np.logical_and(fire_mask(img07, img14), np.logical_not(cloud_mask))\n",
    "        \n",
    "        if np.count_nonzero(fires) != 0:\n",
    "            fires_initial.append(np.count_nonzero(fires))\n",
    "            update_dict_img(fires, cloud_mask, img07, img14, fires_final_control, fires_final_lp, fires_final_um, fires_final_wr, fires_final_ml)\n",
    "\n",
    "            x += 1\n",
    "\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "smoking-sight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.4\n",
      "no_of_fires\n",
      "     Control 11.1 +/- 30.9509\n",
      "     Laplace 13.3 +/- 33.7526\n",
      "     Unsharp Mask 12.35 +/- 31.9892\n",
      "     Wiener 10.55 +/- 32.2768\n",
      "     ESRGAN 10.75 +/- 29.3658\n",
      "dice_score\n",
      "     Control 0.7921 +/- 0.4721\n",
      "     Laplace 0.7746 +/- 0.3952\n",
      "     Unsharp Mask 0.8003 +/- 0.4678\n",
      "     Wiener 0.7209 +/- 0.572\n",
      "     ESRGAN 0.8739 +/- 0.3513\n",
      "TPR\n",
      "     Control 0.8226 +/- 0.5167\n",
      "     Laplace 0.8997 +/- 0.381\n",
      "     Unsharp Mask 0.8964 +/- 0.4756\n",
      "     Wiener 0.7349 +/- 0.6319\n",
      "     ESRGAN 0.8762 +/- 0.4164\n",
      "PPV\n",
      "     Control 0.8339 +/- 0.3383\n",
      "     Laplace 0.716 +/- 0.4405\n",
      "     Unsharp Mask 0.7865 +/- 0.3784\n",
      "     Wiener 0.7891 +/- 0.5251\n",
      "     ESRGAN 0.8829 +/- 0.285\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(fires_initial), 4))\n",
    "results('no_of_fires')\n",
    "results('dice_score')\n",
    "results('TPR')\n",
    "results('PPV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-danish",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
